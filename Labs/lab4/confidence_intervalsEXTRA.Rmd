---
title: 'Foundations for statistical inference - Confidence intervals'
output:
  html_document:
    theme: simplex
    highlight: haddock
    css: ..\labs.css
    toc: yes
---
************

I have added extra comments and code lines in this document. Ideally, go over the regular lab and then read this one. Hope this helps!

***************



<div id="boxedtext">
**Extra note on Setting a seed:** To set the seed you literally choose any number, whatever you want. Setting a seed doesn't mean that every time you sample you will obtain the same number in a consecutive way. If I create a vector  called `x` with values `1-10` and then I draw a random number it will give me any number from `1-10`. If I draw another random number it will give me another number or perhaps the same. For example, it can give me a `5` the first time, and a `2` the second time. If I re-run the two lines it might give me a `3` the first time and a `9` the second time. OR whatever...  _It will change every time_. **However**, if I set a seed ( for example `2222` ) it will give me a `4` the first time and then if I draw another random number it will give me a `2`, then a `9`. So I am getting different random numbers but now I know that setting the seed `2222` will give me those numbers in that order. AND more importantly, when you run the example I am describing here you will get the **same** results.  


```{r, seed-exmaple}
x <- seq(1:10)
set.seed(2222)
sample(x, 1)
sample(x, 1)
sample(x, 1)
```

</div>

```{r global_options, include=FALSE}
knitr::opts_chunk$set(eval = TRUE)
library(dplyr)
library(ggplot2)
library(mosaic)
set.seed(9438024)

normTail <- function (m = 0, s = 1, L = NULL, U = NULL, M = NULL, df = 1000, 
    curveColor = 1, border = 1, col = "#CCCCCC", xlim = NULL, 
    ylim = NULL, xlab = "", ylab = "", digits = 2, axes = 1, 
    detail = 999, xLab = c("number", "symbol"), cex.axis = 1, 
    xAxisIncr = 1, ...) 
{
    if (is.null(xlim)[1]) {
        xlim <- m + c(-1, 1) * 3.5 * s
    }
    temp <- diff(range(xlim))
    x <- seq(xlim[1] - temp/4, xlim[2] + temp/4, length.out = detail)
    y <- dt((x - m)/s, df)/s
    if (is.null(ylim)[1]) {
        ylim <- range(c(0, y))
    }
    #cat(x)
    #cat(y)
    plot(x, y, type = "l", xlim = xlim, ylim = ylim, xlab = xlab, 
        ylab = ylab, axes = FALSE, col = curveColor, ...)
    if (!is.null(L[1])) {
        these <- (x <= L)
        X <- c(x[these][1], x[these], rev(x[these])[1])
        Y <- c(0, y[these], 0)
        polygon(X, Y, border = border, col = col)
    }
    if (!is.null(U[1])) {
        these <- (x >= U)
        X <- c(x[these][1], x[these], rev(x[these])[1])
        Y <- c(0, y[these], 0)
        polygon(X, Y, border = border, col = col)
    }
    if (all(!is.null(M[1:2]))) {
        these <- (x >= M[1] & x <= M[2])
        X <- c(x[these][1], x[these], rev(x[these])[1])
        Y <- c(0, y[these], 0)
        polygon(X, Y, border = border, col = col)
    }
    if (axes == 1 || axes > 2) {
        if (xLab[1] == "symbol") {
            xAt <- m + (-3:3) * s
            xLab <- expression(mu - 3 * sigma, mu - 2 * sigma, 
                mu - sigma, mu, mu + sigma, mu + 2 * sigma, mu + 
                  3 * sigma)
        }
        else if (xLab[1] != "number") {
            stop("Argument \"xLab\" not recognized.\n")
        }
        else {
            temp <- seq(xAxisIncr, max(abs(xlim - m))/s, xAxisIncr) * 
                s
            xAt <- m + c(-temp, 0, temp)
            xLab <- round(xAt, digits = digits)
        }
    }
    if (axes > 2) {
        axis(1, at = xAt, labels = xLab, cex.axis = cex.axis)
        buildAxis(2, c(y, 0), n = 3, nMax = 3, cex.axis = cex.axis)
    }
    else if (axes > 1) {
        buildAxis(2, c(y, 0), n = 3, nMax = 3, cex.axis = cex.axis)
    }
    else if (axes > 0) {
        axis(1, at = xAt, labels = xLab, cex.axis = cex.axis)
    }
    abline(h = 0)
}
```




## Sampling from Ames, Iowa




## The data

The main point here in relation to the data is that this  data-set is actually the **population**. We rarely have that luxury.



```{r}
load(url("https://raw.githubusercontent.com/GarciaRios/govt_3990/gh-pages/Labs/lab4/data/ames.RData"))
```

- We start drawing a simple random sample of size 60 from the 
population.  (if this doesn't work, it's because you have not loaded `dplyr`)




```{r sample}
n <- 100
samp <- sample_n(ames, n)

```

- While the data-set has many housing variables, we are going to focus on the size of the house, represented by the variable `Lot.Area`.

```{r sample - Area}
samp %>% select(1:7) %>% 
  slice(1:15)
```  
  


1.  Describe the distribution of homes in your sample. What would you say is the
    "typical" size within your sample? Also state precisely what you interpreted 
    "typical" to mean. later



1.  Would you expect another classmate's distribution to be identical to yours? 
    Would you expect it to be similar? Why or why not?

## Confidence intervals

 - Make sure you go over this section and read carefully, it's important


Return for a moment to the question that first motivated this lab: based on 
this sample, what can we infer about the population? Based only on this single 
sample, the best estimate of the average living area of houses sold in Ames 
would be the sample mean, usually denoted as $\bar{x}$ (here we're calling it 
`x_bar`). That serves as a good **point estimate** but it would be useful 
to also communicate how uncertain we are of that estimate. This uncertainty
can be quantified using a **confidence interval**.



A confidence interval for a population mean is of the following form
\[ \bar{x} + z^\star \frac{s}{\sqrt{n}} \]

- You should  already know this formula but here it is again as a reminder
- By now you should be comfortable with calculating the mean and standard deviation of 
a sample in R. And we know that the sample size is 60. So the only remaining building block is finding the appropriate critical value for a given confidence level.

- Instead of using the tables you have been  using so far, you are going to use the `qnorm` function for this task, which will give the critical value associated
with a given percentile under the normal distribution. Remember that confidence levels
and percentiles are not equivalent. For example, a 95% confidence level refers to the
middle 95% of the distribution, and the critical value associated with this area will
correspond to the 97.5th percentile.

- We have seen this  graph to illustrate what a 95% CI would mean, so hopefully this is familiar to you.


```{r eval=TRUE, echo=FALSE, fig.height=3, fig.width=5, fig.align='center'}
par(mar = c(3,0,0,0))
normTail(M = c(-1.96, 1.96), col = "#569BBD", axes = FALSE)
axis(1, at = c(-3, -1.96, 0, 1.96, 3), labels = c(NA, -1.96, 0, 1.96, NA), 
     cex.axis = 1.5)
text(x = 0, y = 0.15, "95%", cex = 1.5, col = "white")
text(x = -2.8, y = 0.05, "2.5%", cex = 1.5)
text(x = 2.8, y = 0.05, "2.5%", cex = 1.5)
graphics::arrows(-3.7, 0.25, 1.96, 0.25, col = "red", lwd = 3, code = 3)
text(x = -1.4, y = 0.275, "97.5%", cex = 1.5, col = "red")
```

We can find the critical value for a 95% confidence interval using
```{r z_star_95}
z_star_95 <- qnorm(0.975)
z_star_95
```
which is roughly equal to the value critical value 1.96 that you're likely
familiar with by now.

Let's finally calculate the confidence interval.

```{r ci}
samp %>%
  summarise(lower = mean(Lot.Area) - z_star_95 * (sd(Lot.Area) / sqrt(n)),
            upper = mean(Lot.Area) + z_star_95 * (sd(Lot.Area) / sqrt(n)))
```

In addition to calculating the lower and upper bounds, for teaching purposes, it might be useful to also estimate the mean right there, Like this

```{r ci-w.mean}
samp %>%
  summarise(lower = mean(Lot.Area) - z_star_95 * (sd(Lot.Area) / sqrt(n)),
            mean = mean(Lot.Area),
            upper = mean(Lot.Area) + z_star_95 * (sd(Lot.Area) / sqrt(n)))
```
 -  You can see that the estimated mean obviously falls right in the middle.. .

To recap: even though we don't know what the full population looks like, we're 95% 
confident that the true average size of houses in Ames lies between the values *lower* 
and *upper*. There are a few conditions that must be met for this interval to be valid.




1.  For the confidence interval to be valid, the sample mean must be normally 
    distributed and have standard error $s / \sqrt{n}$. What conditions must be 
    met for this to be true?

## Confidence levels

1.  What does "95% confidence" mean?

Again, in this case we have the rare luxury of knowing the true population mean since we 
have data on the entire population. Let's calculate this value so that
we can determine if our confidence intervals actually capture it. We'll store it in a data frame called `params` (short for population parameters), and name it `mu`.

```{r pop-mean}
params <- ames %>%
  summarise(mu = mean(Lot.Area))
```

- Again, we will be using different seeds so if you are working in groups your `mu` might not be captured by your sample, and perhaps  your friend's sample does capture it, that's fine just keep going you'll see why...
 
1.  Does your confidence interval capture the true average size of houses in 
    Ames?  does your neighbor's interval capture this value? 

1.  Each student should have gotten a slightly different confidence interval. What 
    proportion of those intervals would you expect to capture the true population 
    mean? Why?

Using R, we're going to collect many samples to learn more about how sample 
means and confidence intervals vary from one sample to another.

Here is the rough outline:

-   Obtain a random sample.
-   Calculate the sample's mean and standard deviation, and use these to calculate
and store the lower and upper bounds of the confidence intervals.
-   Repeat these steps 50 times.

We can accomplish this using the `do` function. The following lines of code takes 50
random samples of size `n` from population (and remember we defined $n = 60$ earlier),
and computes the upper and lower bounds of the confidence intervals based on these
samples.

```{r calculate-50-cis}
ci <- do(50) * ames %>%
                  sample_n(n) %>%  
  summarise(lower = mean(Lot.Area) - z_star_95 * (sd(Lot.Area) / sqrt(n)), 
            upper = mean(Lot.Area) + z_star_95 * (sd(Lot.Area) / sqrt(n)))
```

Let's view the first five intervals:

```{r first-five-intervals}
ci %>%
  slice(1:5)
```

Next we'll create a plot similar to Figure 4.8 on page 175 of [OpenIntro Statistics, 3rd
Edition](https://www.openintro.org/os). First step will be to create a new variable in 
the `ci` data frame that indicates whether the interval does or does not capture the 
true population mean. Note that capturing this value would mean the lower bound of the
confidence interval is below the value and upper bound of the confidence interval is
above the value. Remember that we create new variables using the `mutate` function.

```{r capture-mu}
ci <- ci %>%
  mutate(capture_mu = ifelse(lower < params$mu & upper > params$mu, "yes", "no"))


```


- I don't know if you are struggling with `iflelse`... it's not very intuitive so hopefully this extra explanation helps.

The `ifelse`  takes three arguments: first is a logical statement, second is the value we want if the logical statement yields a true result, and the third is the value we want if the logical statement yields a false result.

 - (In this case  we use `mutate` to create a variable that would have two values: "yes" and "no". The values would be assigned using `iflese`:  if the lower bound is less than  `mu` AND  the upper bound greater than `mu`, the assigned value would be "yes", OTHERWISE it will be "no")

We now have all the information we need to create the plot, but we need to re-organize
our data a bit for easy plotting. Specifically, we need to organize the data in a new
data frame where each row represents one bound, as opposed to one interval. So this

~~~
     lower    upper capture_mu
1 1355.688 1559.545        yes
2 1413.661 1681.673        yes
3 1372.159 1631.807        yes
...
~~~

should instead look like

~~~
  ci_id ci_bounds capture_mu
1     1  1355.688        yes
2     2  1413.661        yes
3     3  1372.159        yes
4     1  1559.545        yes
5     2  1681.673        yes
6     3  1631.807        yes
...
~~~

We can accomplish this using the following:

```{r create-ci-data-for-plot}
ci_data <- data.frame(ci_id = c(1:50, 1:50),
                      ci_bounds = c(ci$lower, ci$upper),
                      capture_mu = c(ci$capture_mu, ci$capture_mu))
```

And finally we can create the plot using the following:



```{r plot-ci, eval= F}
ggplot(ci_data, aes(x = ci_bounds, y = ci_id, 
      group = ci_id, color = capture_mu)) +
  geom_point(size = 2) +  # add points at the ends, size = 2
  geom_line() +           # connect with lines
  geom_vline(xintercept = params$mu, color = "darkgray") # draw vertical line
```

 - At this point if you created the plot you should be able to understand the purpose of the lab, it should be more intuitive at this point.


1.  What proportion of your confidence intervals include the true population mean? Is 
    this proportion exactly equal to the confidence level? If not, explain why. Make 
    sure to include your plot in your answer.

* * *

<div class="oyo">

## On your own

-   Pick a confidence level of your choosing, provided it is not 95%. What is 
    the appropriate critical value?

-   Calculate 50 confidence intervals at the confidence level you chose in the 
    previous question, and plot all intervals on one plot, and calculate the proportion 
    of intervals that include the true population mean. How does this percentage compare 
    to the confidence level selected for the intervals? Make 
    sure to include your plot in your answer.
</div>

<div id="license">
Science should be free and open source! 
Attribution-ShareAlike 3.0 Unported](http://creativecommons.org/licenses/by-sa/3.0).
</div>