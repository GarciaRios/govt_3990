% -*- TeX-engine: xetex; eval: (auto-fill-mode 0); eval: (visual-line-mode 1); -*-
% Compile with XeLaTeX

%%%%%%%%%%%%%%%%%%%%%%%
% Option 1: Slides: (comment for handouts)   %
%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[slidestop,compress,mathserif,12pt,t,professionalfonts,xcolor=table]{beamer}

% solution stuff
\newcommand{\solnMult}[1]{
\only<1>{#1}
\only<2->{\red{\textbf{#1}}}
}
\newcommand{\soln}[1]{\textit{#1}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Option 2: Handouts, without solutions (post before class)    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \documentclass[11pt,containsverbatim,handout,xcolor=xelatex,dvipsnames,table]{beamer}
%
% % handout layout
% \usepackage{pgfpages}
% \pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=5mm]
%
%% % solution stuff
% \newcommand{\solnMult}[1]{#1}
% \newcommand{\soln}[1]{}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Option 3: Handouts, with solutions (may post after class if need be)    %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% \documentclass[11pt,containsverbatim,handout,xcolor=xelatex,dvipsnames,table]{beamer}

% % handout layout
% \usepackage{pgfpages}
% \pgfpagesuselayout{4 on 1}[letterpaper,landscape,border shrink=5mm]

% % solution stuff
% \newcommand{\solnMult}[1]{\red{\textbf{#1}}}
% \newcommand{\soln}[1]{\textit{#1}}

%%%%%%%%%%
% Load style file, defaults  %
%%%%%%%%%%

\input{../../lec_style.tex}
\input{../../definitions_default.tex}
% ALT ALT
% \input{../../definitions_custom.tex}

%%%%%%%%%%%
% Cover slide info    %
%%%%%%%%%%%

\title{Unit 7: Multiple linear regression}
\subtitle{1. Introduction to multiple linear regression  }
\author{\CourseName}
\date{}
\institute{\InstituteName}


%%%%%%%%%%%%%%%%%%%%%%%%%
% Begin document and set Helvetica Neue font   %
%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\fontspec[Ligatures=TeX]{Helvetica Neue Light}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Title Page

\begin{frame}[plain]

\titlepage

\vfill

{\scriptsize \webLink{\PersonalSite}{Dr. \LastName{}} \hfill Slides posted at  \webURL{\CourseSite}}

\addtocounter{framenumber}{-1} 

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Housekeeping}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Announcements}

\begin{itemize}

\item Project questions?

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Main ideas}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{In MLR everything is conditional on all other variables in the model}
\label{mi1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{(1) In MLR everything is conditional on all other variables in the model}

\begin{itemize}

\item All estimates in a MLR for a given variable are conditional on all other variables being in the model.

\item \textbf{Slope:} 
\begin{itemize}
\item Numerical $x$: \hl{All else held constant}, for one unit increase in $x_i$, $y$ is expected to be higher / lower on average by $b_i$ units.
\item Categorical $x$: \hl{All else held constant}, the predicted difference in $y$ for the baseline and given levels of $x_i$ is $b_i$.
\end{itemize}

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Data from the ACS}

A random sample of 783 observations from the 2012 ACS.

{\scriptsize
\begin{enumerate}
\item \texttt{income}: Yearly income (wages and salaries)
\item \texttt{employment}: Employment status, not in labor force, unemployed, or employed
\item \texttt{hrs\_work}: Weekly hours worked
\item \texttt{race}: Race, White, Black, Asian, or other
\item \texttt{age}: Age
\item \texttt{gender}: gender, male or female
\item \texttt{citizens}: Whether respondent is a US citizen or not
\item \texttt{time\_to\_work}: Travel time to work
\item \texttt{lang}: Language spoken at home, English or other
\item \texttt{married}: Whether respondent is married or not
\item \texttt{edu}: Education level, hs or lower, college, or grad
\item \texttt{disability}: Whether respondent is disabled or not
\item \texttt{birth\_qrtr}: Quarter in which respondent is born, jan thru mar, apr thru jun, jul thru sep, or oct thru dec 
\end{enumerate}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[shrink]

\activity{MLR interpretations}{
\begin{enumerate}
\item Interpret the intercept.
\item Interpret the slope for hrs\_work.
\item Interpret the slope for gender.
\end{enumerate}
}

\begin{center}
{\tiny
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -15342.76 & 11716.57 & -1.31 & 0.19 \\ 
  hrs\_work & 1048.96 & 149.25 & 7.03 & 0.00 \\ 
  raceblack & -7998.99 & 6191.83 & -1.29 & 0.20 \\ 
  raceasian & 29909.80 & 9154.92 & 3.27 & 0.00 \\ 
  raceother & -6756.32 & 7240.08 & -0.93 & 0.35 \\ 
  age & 565.07 & 133.77 & 4.22 & 0.00 \\ 
  genderfemale & -17135.05 & 3705.35 & -4.62 & 0.00 \\ 
  citizenyes & -12907.34 & 8231.66 & -1.57 & 0.12 \\ 
  time\_to\_work & 90.04 & 79.83 & 1.13 & 0.26 \\ 
  langother & -10510.44 & 5447.45 & -1.93 & 0.05 \\ 
  marriedyes & 5409.24 & 3900.76 & 1.39 & 0.17 \\ 
  educollege & 15993.85 & 4098.99 & 3.90 & 0.00 \\ 
  edugrad & 59658.52 & 5660.26 & 10.54 & 0.00 \\ 
  disabilityyes & -14142.79 & 6639.40 & -2.13 & 0.03 \\ 
  birth\_qrtrapr thru jun & -2043.42 & 4978.12 & -0.41 & 0.68 \\ 
  birth\_qrtrjul thru sep & 3036.02 & 4853.19 & 0.63 & 0.53 \\ 
  birth\_qrtroct thru dec & 2674.11 & 5038.45 & 0.53 & 0.60 \\ 
   \hline
\end{tabular}
}
\end{center}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Categorical predictors and slopes for (almost) each level}
\label{mi2}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{(2) Categorical predictors and slopes for (almost) each level}

\begin{itemize}

\item Each categorical variable, with $k$ levels, added to the model results in $k-1$ parameters being estimated.

\item It only takes $k-1$ columns to code a categorical variable with $k$ levels as 0/1s.

\end{itemize}

\pause

{\scriptsize

\twocol{0.4}{0.6}{
\begin{center}
Citizen: yes / no ($k = 2$) \\
\pause
Baseline: no \\
$\:$ \\
$\:$ \\
\pause
\begin{tabular}{l | c}
Respondent		& citizen:yes \\
\hline
\pause
1, Citizen	& 1 \\
\pause
2, Not-citizen	& 0 \\
\end{tabular}
\end{center}
}
{
\pause
\begin{center}
Race: ($k = 4$) \\
\pause
Baseline: White
$\:$ \\
$\:$ \\
\pause
\begin{tabular}{l | c | c | c}
Respondent	& race:black	& race:asian & race:other \\
\hline
\pause
1, White		& 0 	& 0	& 0 \\
\pause
2, Black		& 1 	& 0	& 0 \\
\pause
3, Asian 		& 0 	& 1	& 0 \\
\pause
4, Other		& 0 	& 0	& 1 \\
\end{tabular}
\end{center}
}

}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}

\clicker{{\small All else held constant, how do incomes of those born January thru March compare to those born April thru June?}}

\begin{center}
{\tiny
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -15342.76 & 11716.57 & -1.31 & 0.19 \\ 
  hrs\_work & 1048.96 & 149.25 & 7.03 & 0.00 \\ 
  raceblack & -7998.99 & 6191.83 & -1.29 & 0.20 \\ 
  raceasian & 29909.80 & 9154.92 & 3.27 & 0.00 \\ 
  raceother & -6756.32 & 7240.08 & -0.93 & 0.35 \\ 
  age & 565.07 & 133.77 & 4.22 & 0.00 \\ 
  genderfemale & -17135.05 & 3705.35 & -4.62 & 0.00 \\ 
  citizenyes & -12907.34 & 8231.66 & -1.57 & 0.12 \\ 
  time\_to\_work & 90.04 & 79.83 & 1.13 & 0.26 \\ 
  langother & -10510.44 & 5447.45 & -1.93 & 0.05 \\ 
  marriedyes & 5409.24 & 3900.76 & 1.39 & 0.17 \\ 
  educollege & 15993.85 & 4098.99 & 3.90 & 0.00 \\ 
  edugrad & 59658.52 & 5660.26 & 10.54 & 0.00 \\ 
  disabilityyes & -14142.79 & 6639.40 & -2.13 & 0.03 \\ 
  birth\_qrtrapr thru jun & -2043.42 & 4978.12 & -0.41 & 0.68 \\ 
  birth\_qrtrjul thru sep & 3036.02 & 4853.19 & 0.63 & 0.53 \\ 
  birth\_qrtroct thru dec & 2674.11 & 5038.45 & 0.53 & 0.60 \\ 
   \hline
\end{tabular}
}
\end{center}

{\footnotesize
All else held constant, those born Jan thru Mar make, on average,
\begin{multicols}{4}
\begin{enumerate}[(a)]
\item \$2,043.42 less
\item \solnMult{\$2,043.42 more}
\item \$4978.12 less
\item \$4978.12 more
\end{enumerate}
\end{multicols}
\vspace{-0.5cm}
than those born Apr thru Jun.
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Inference for MLR: model as a whole + individual slopes}
\label{mi3}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{(3) Inference for MLR: model as a whole + individual slopes}

\begin{itemize}

\item Inference for the model as a whole: F-test, $df_1 = p$, $df_2 = n - k - 1$
\begin{itemize}
\item[$H_0:$] $\beta_1 = \beta_2 = \cdots = \beta_k = 0$
\item[$H_A:$] At least one of the $\beta_i \ne 0$
\end{itemize}

\pause

\item Inference for each slope: T-test, $df = n - k - 1$
\begin{itemize}
\item HT:
\begin{itemize}
\item[$H_0:$] $\beta_1 = 0$, when all other variables are included in the model
\item[$H_A:$] $\beta_1 \ne 0$, when all other variables are included in the model
\end{itemize}
\item CI: $b_1 \pm T^\star_{df} SE_{b_1}$
\end{itemize}

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Model output}

{\tiny
\begin{Verbatim}[frame=single, formatcom=\color{gray}]
Coefficients:
                        Estimate Std. Error t value Pr(>|t|)    
(Intercept)            -15342.76   11716.57  -1.309 0.190760    
hrs_work                 1048.96     149.25   7.028 4.63e-12 ***
raceblack               -7998.99    6191.83  -1.292 0.196795    
raceasian               29909.80    9154.92   3.267 0.001135 ** 
raceother               -6756.32    7240.08  -0.933 0.351019    
age                       565.07     133.77   4.224 2.69e-05 ***
genderfemale           -17135.05    3705.35  -4.624 4.41e-06 ***
citizenyes             -12907.34    8231.66  -1.568 0.117291    
time_to_work               90.04      79.83   1.128 0.259716    
langother              -10510.44    5447.45  -1.929 0.054047 .  
marriedyes               5409.24    3900.76   1.387 0.165932    
educollege              15993.85    4098.99   3.902 0.000104 ***
edugrad                 59658.52    5660.26  10.540  < 2e-16 ***
disabilityyes          -14142.79    6639.40  -2.130 0.033479 *  
birth_qrtrapr thru jun  -2043.42    4978.12  -0.410 0.681569    
birth_qrtrjul thru sep   3036.02    4853.19   0.626 0.531782    
birth_qrtroct thru dec   2674.11    5038.45   0.531 0.595752    

Residual standard error: 48670 on 766 degrees of freedom
  (60 observations deleted due to missingness)
Multiple R-squared:  0.3126,	Adjusted R-squared:  0.2982 
F-statistic: 21.77 on 16 and 766 DF,  p-value: < 2.2e-16
\end{Verbatim}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\clicker{True / False: The F test yielding a significant result means the model fits the data well.}

\begin{enumerate}[(a)]
\item True
\item \solnMult{False}
\end{enumerate}

\vspace{1cm}

\only<2 | handout:0>{
\soln{The F test yielding a significant result doesn't mean the model fits the data well, it just means at least one of the $\beta$s is non-zero. Whether or not the model fit the data well is evaluated based on model diagnostics.
}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\clicker{True / False:  The F test not yielding a significant result means individual variables included in the model are not good predictors of $y$.}

\begin{enumerate}[(a)]
\item True
\item \solnMult{False}
\end{enumerate}

\vspace{1cm}

\only<2 | handout:0>{
\soln{The F test not yielding a significant result doesn't mean individuals variables included in the model are not good predictors of $y$, it just means that the \underline{combination} of these variables doesn't yield a good model.
}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]
\frametitle{Significance also depends on what else is in the model}

{\tiny
\begin{Verbatim}[frame=single, formatcom=\color{gray}]
Model 1:                Estimate Std. Error t value Pr(>|t|)    
(Intercept)            -15342.76   11716.57  -1.309 0.190760    
hrs_work                 1048.96     149.25   7.028 4.63e-12 
raceblack               -7998.99    6191.83  -1.292 0.196795    
raceasian               29909.80    9154.92   3.267 0.001135 
raceother               -6756.32    7240.08  -0.933 0.351019   
age                       565.07     133.77   4.224 2.69e-05 
genderfemale           -17135.05    3705.35  -4.624 4.41e-06 
citizenyes             -12907.34    8231.66  -1.568 0.117291    
time_to_work               90.04      79.83   1.128 0.259716    
langother              -10510.44    5447.45  -1.929 0.054047  
marriedyes               5409.24    3900.76   1.387 0.165932 <----    
educollege              15993.85    4098.99   3.902 0.000104 
edugrad                 59658.52    5660.26  10.540  < 2e-16 
disabilityyes          -14142.79    6639.40  -2.130 0.033479   
birth_qrtrapr thru jun  -2043.42    4978.12  -0.410 0.681569    
birth_qrtrjul thru sep   3036.02    4853.19   0.626 0.531782    
birth_qrtroct thru dec   2674.11    5038.45   0.531 0.595752    
\end{Verbatim}
}
\pause
{\tiny
\begin{Verbatim}[frame=single, formatcom=\color{gray}]
Model 2:     Estimate Std. Error t value Pr(>|t|)    
(Intercept)  -22498.2     8216.2  -2.738  0.00631
hrs_work       1149.7      145.2   7.919 7.60e-15
raceblack     -7677.5     6350.8  -1.209  0.22704    
raceasian     38600.2     8566.4   4.506 7.55e-06
raceother     -7907.1     7116.2  -1.111  0.26683    
age             533.1      131.2   4.064 5.27e-05
genderfemale -15178.9     3767.4  -4.029 6.11e-05
marriedyes     8731.0     3956.8   2.207  0.02762 <----
\end{Verbatim}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Adjusted $R^2$ applies a penalty for additional variables}
\label{mi4}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{(4) Adjusted $R^2$ applies a penalty for additional variables}

\begin{itemize}

\item When \underline{any} variable is added to the model $R^2$ increases.

\pause

\item But if the added variable doesn't really provide any new information, or is completely unrelated, adjusted $R^2$ does not increase.

\end{itemize}

\pause

\formula{Adjusted $R^2$}
{\[ R^2_{adj} = 1 - \pr{ \frac{ SS_{Error} }{ SS_{Total} } \times \frac{n - 1}{n - k - 1} } \]
where $n$ is the number of cases and $k$ is the number of sloped estimated in the model.
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}[fragile]

{\tiny
\begin{Verbatim}[frame=single, formatcom=\color{gray}]
Analysis of Variance Table

Response: income
              Df     Sum Sq    Mean Sq  F value    Pr(>F)    
hrs_work       1 3.0633e+11 3.0633e+11 129.3025 < 2.2e-16 ***
race           3 7.1656e+10 2.3885e+10  10.0821 1.608e-06 ***
age            1 7.6008e+10 7.6008e+10  32.0836 2.090e-08 ***
gender         1 4.8665e+10 4.8665e+10  20.5418 6.767e-06 ***
citizen        1 1.1135e+09 1.1135e+09   0.4700   0.49319    
time_to_work   1 3.5371e+09 3.5371e+09   1.4930   0.22213    
lang           1 1.2815e+10 1.2815e+10   5.4094   0.02029 *  
married        1 1.2190e+10 1.2190e+10   5.1453   0.02359 *  
edu            2 2.7867e+11 1.3933e+11  58.8131 < 2.2e-16 ***
disability     1 1.0852e+10 1.0852e+10   4.5808   0.03265 *  
birth_qrtr     3 3.3060e+09 1.1020e+09   0.4652   0.70667    
Residuals    766 1.8147e+12 2.3691e+09          
Total        782 2.6399e+12             
\end{Verbatim}
}

\[ R^2_{adj} = 1 - \pr{ \frac{1.8147e+12}{ 2.6399e+12 } \times \frac{783 - 1}{783 - 16 - 1} } \approx 1 - 0.7018 = 0.2982 \]

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\clicker{True / False: For a model with at least one predictor, $R^2_{adj}$ will always be smaller than $R^2$.}

\begin{enumerate}[(a)]
\item \solnMult{True}
\item False
\end{enumerate}

\vspace{1cm}

\only<2 | handout:0>{
\soln{Because $k$ is never negative, $R^2_{adj}$ will always be smaller than $R^2$.
\[ R^2_{adj} = 1 - \pr{ \frac{ SS_{Error} }{ SS_{Total} } \times \frac{n - 1}{n - k - 1} } \]
}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\clicker{True / False: Adjusted $R^2$ tells us the percentage of variability in the response variable explained by the model.}

\begin{enumerate}[(a)]
\item True
\item \solnMult{False}
\end{enumerate}
\vspace{1cm}

\only<2 | handout:0>{
\soln{$R^2$ tells us the percentage of variability in the response variable explained by the model, adjusted $R^2$ is only useful for model selection.
}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Avoid collinearity in MLR}
\label{mi5}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{(5) Avoid collinearity in MLR}

\begin{itemize}

\item Two predictor variables are said to be collinear when they are correlated, and this \hl{collinearity} (also called \hl{multicollinearity}) complicates model estimation. \\
\Remember{Predictors are also called explanatory or \underline{independent} variables, so they should be independent of each other.}

\pause

\item We don't like adding predictors that are associated with each other to the model, because often times the addition of such variable brings nothing to the table. Instead, we prefer the simplest best model, i.e. \hl{parsimonious} model.

\pause

\item In addition, addition of collinear variables can result in unreliable estimates of the slope parameters.

\pause

\item While it's impossible to avoid collinearity from arising in observational data, experiments are usually designed to control for correlated predictors.

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Model selection criterion depends on goal: significance vs. prediction}
\label{mi6}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{(6) Model selection criterion depends on goal: significance vs. prediction}

\begin{itemize}

\item If the goal is to find the set of statistically predictors of $y$ $\rightarrow$ use p-value selection.

\pause

\item If the goal is to do better prediction of $y$ $\rightarrow$ use adjusted $R^2$ selection.

\pause

\item Either way, can use \hl{backward elimination} or \hl{forward selection}.

\pause

\item Expert opinion and focus of research might also demand that a particular variable be included in the model.

\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\clicker{Using the p-value approach, which variable would you remove from the model first?}

\begin{center}
{\tiny
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -15342.76 & 11716.57 & -1.31 & 0.19 \\ 
  hrs\_work & 1048.96 & 149.25 & 7.03 & 0.00 \\ 
  raceblack & -7998.99 & 6191.83 & -1.29 & 0.20 \\ 
  raceasian & 29909.80 & 9154.92 & 3.27 & 0.00 \\ 
  raceother & -6756.32 & 7240.08 & -0.93 & 0.35 \\ 
  age & 565.07 & 133.77 & 4.22 & 0.00 \\ 
  genderfemale & -17135.05 & 3705.35 & -4.62 & 0.00 \\ 
  citizenyes & -12907.34 & 8231.66 & -1.57 & 0.12 \\ 
  time\_to\_work & 90.04 & 79.83 & 1.13 & 0.26 \\ 
  langother & -10510.44 & 5447.45 & -1.93 & 0.05 \\ 
  marriedyes & 5409.24 & 3900.76 & 1.39 & 0.17 \\ 
  educollege & 15993.85 & 4098.99 & 3.90 & 0.00 \\ 
  edugrad & 59658.52 & 5660.26 & 10.54 & 0.00 \\ 
  disabilityyes & -14142.79 & 6639.40 & -2.13 & 0.03 \\ 
  birth\_qrtrapr thru jun & -2043.42 & 4978.12 & -0.41 & 0.68 \\ 
  birth\_qrtrjul thru sep & 3036.02 & 4853.19 & 0.63 & 0.53 \\ 
  birth\_qrtroct thru dec & 2674.11 & 5038.45 & 0.53 & 0.60 \\ 
   \hline
\end{tabular}
}
\end{center}

\begin{multicols}{2}
\begin{enumerate}[(a)]
\item race:other
\item race
\item time\_to\_work
\item birth\_qrtr:apr thru jun
\item \solnMult{birth\_qrtr}
\item[]
\end{enumerate}
\end{multicols}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\clicker{Using the p-value approach, which variable would you remove from the model next?}

\begin{center}
{\tiny
\begin{tabular}{rrrrr}
  \hline
 & Estimate & Std. Error & t value & Pr($>$$|$t$|$) \\ 
  \hline
(Intercept) & -14022.48 & 11137.08 & -1.26 & 0.21 \\ 
  hrs\_work & 1045.85 & 149.05 & 7.02 & 0.00 \\ 
  raceblack & -7636.32 & 6177.50 & -1.24 & 0.22 \\ 
  raceasian & 29944.35 & 9137.13 & 3.28 & 0.00 \\ 
  raceother & -7212.57 & 7212.25 & -1.00 & 0.32 \\ 
  age & 559.51 & 133.27 & 4.20 & 0.00 \\ 
  genderfemale & -17010.85 & 3699.19 & -4.60 & 0.00 \\ 
  citizenyes & -13059.46 & 8219.99 & -1.59 & 0.11 \\ 
  time\_to\_work & 88.77 & 79.73 & 1.11 & 0.27 \\ 
  langother & -10150.41 & 5431.15 & -1.87 & 0.06 \\ 
  marriedyes & 5400.41 & 3896.12 & 1.39 & 0.17 \\ 
  educollege & 16214.46 & 4089.17 & 3.97 & 0.00 \\ 
  edugrad & 59572.20 & 5631.33 & 10.58 & 0.00 \\ 
  disabilityyes & -14201.11 & 6628.26 & -2.14 & 0.03 \\ 
   \hline
\end{tabular}
}
\end{center}

\begin{multicols}{2}
\begin{enumerate}[(a)]
\item married
\item race
\item race:other
\item race:black
\item \solnMult{time\_to\_work}
\item[]
\end{enumerate}
\end{multicols}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsection{Conditions for MLR are (almost) the same as conditions for SLR}
\label{mi7}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{(7) Conditions for MLR are (almost) the same as conditions for SLR}

\hl{Important regardless of doing inference}
\begin{itemize}
\item Linearity $\rightarrow$ randomly scattered residuals around 0 in the residuals plot
\end{itemize}

\pause

\hl{Important for doing inference}
\begin{itemize}
\item Nearly normally distributed residuals $\rightarrow$ histogram or normal probability plot of residuals
\item Constant variability of residuals (\hl{homoscedasticity}) $\rightarrow$ no fan shape in the residuals plot
\item Independence of residuals (and hence observations) $\rightarrow$ depends on data collection method, often violated for time-series data
\pause
\item Also important to make sure that your explanatory variables are not \hl{collinear}
\end{itemize}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{}

\clicker{Which of the following is the appropriate plot for checking the homoscedasticity condition in MLR?}

\begin{enumerate}[(a)]
\item \solnMult{scatterplot of residuals vs. $\hat{y}$}
\item scatterplot of residuals vs. $x$
\item histogram of residuals
\item normal probability plot of residuals
\item scatterplot of residuals vs. order of data collection
\end{enumerate}
\vspace{1cm}

\only<2 | handout:0>{
\soln{Plotting residuals against $\hat{y}$ (predicted, or fitted, values of $y$) allows us to evaluate the whole model as a whole as opposed to homoscedasticity with regards to just one of the explanatory variables in the model.
}
}

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Summary}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{frame}
\frametitle{Summary of main ideas}

\vfill

\begin{enumerate}

\item \nameref{mi1}

\item \nameref{mi2}

\item \nameref{mi3}

\item \nameref{mi4}

\item \nameref{mi5}

\item \nameref{mi6}

\item \nameref{mi7}

\end{enumerate}

\vfill

\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\end{document}